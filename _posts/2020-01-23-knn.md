---
layout: post
title: "K-Nearest Neighbours"
subtitle: "Very simple inefficient algorithm for classification"
excerpt: "KNN classifier is a nonparametric lazy classifier. In nonparametric classification the algorithm does not assume any specific distribution for the data sets."
date: 2020-01-23 23:45:13 -0400
background: "/img/posts/2020-01-23-knn/background.jpg"
categories: ["data-mining", "classification"]
author: "Polla Fattah"
---

<style>
  .responsive-img {
  width: 100%;
  max-width: 500px;
  height: auto;
  display: block;
  margin: 0 auto;
}
.footnotes {
  font-size: 0.7em;
  margin-top: 1em;
}
</style>


## K-Nearest Neighbours

The K-Nearest Neighbours (KNN) classifier is a nonparametric lazy classifier. In nonparametric classification the algorithm does not assume any specific distribution for the data sets. Lazy classifiers do not generalise the classification model and calculate the class of the item at the time of testing instead of training, which makes training very efficient by reducing the cost of testing time [^18].

KNN estimates items' classes according to their nearest neighbours. The majority of the K nearest neighbours decide the class of the input item. An odd number of for K is selected (between 3 to 9) to prevent ties. The nearest neighbours are decided using one of the distance measures (e.g. Euclidean distance), as shown in Figure \ref{fig:KNN} [^2].

\begin{figure}[!h]

    \includegraphics[scale=0.9]{images/chapter2/KNN.png}
    \caption{K-Nearest Neighbour Classification with K = 5}
    \label{fig:KNN}

\end{figure}

To prevent attribute bias due to different magnitudes of values it is strongly preferred to normalise all attributes before classification. Non-numerical attributes can also be used with KNN classification, similar attributes with the K neighbours have zero distance, and different attributes have the distance of 1 [^2].

While this classification algorithm is different from rule-based classifiers, we used a variation of this classification for temporal attributes, as explained in chapter six, as a comparison with our proposed classification algorithm to test the performance difference between the algorithms.

## Classification Performance Measures

Multiple methods exist to measure the performance of a classification algorithm and classify a data set into two classes, positive and classified. The terminology was developed in the medical field, where positive denotes the presence of a disease and negative indicates its absence [^19].

In a test data set D with n instances, a classifier tries to identify the class of instances for binary classifiers, whereby four possibilities exist. These possibilities for any classifier can be demonstrated as a confusion matrix, which is shown in Table \ref{tab:confusionMatrix}, and explained below [^2]:

\begin{itemize}
\item \acrfull{tp}: Number of correctly identified positive cases by the classifier.
\item \acrfull{fp}: Number of incorrectly identified cases as positive but their true labels are negative.
\item \acrfull{tn}: Number of correctly identified negative cases by the classifier.
\item \acrfull{fn}: Number of incorrectly identified cases as negative but their true labels are positive.
\end{itemize}

\begin{table}[!h]
\centering
\begin{tabular}{l|l|c|c|c}
\multicolumn{2}{c}{}&\multicolumn{2}{c}{True diagnosis}&\\
\cline{3-4}
\multicolumn{2}{c|}{}&Positive&Negative&\multicolumn{1}{c}{Total}\\
\cline{2-4}
\multirow{2}{\*}{Screening test}& Positive & TP & FP & $a+b$\\
\cline{2-4}
& Negative & FN & TN & $c+d$\\
\cline{2-4}
\multicolumn{1}{c}{} & \multicolumn{1}{c}{Total} & \multicolumn{1}{c}{$a+c$} & \multicolumn{1}{c}{$b+d$} & \multicolumn{1}{c}{$N$}\\
\end{tabular}
\caption{Confusion Matrix}
\label{tab:confusionMatrix}
\end{table}

To measure the overall performance of a classifier directly from the confusion matrix we can calculate the accuracy and error rates. The accuracy of a classifier is the fraction of correctly classified instances so that: $Accuracy = \frac{TP + TN}{n}$. In contrast, the fraction of all misclassified instances comprise the
error rate which is: $Error Rate = \frac{FP + FN}{n}$ [^19].

To measure class-specific performance we can use recall and precision. Recall is the ratio of correctly predicted number of a class labels to the real number of instances of that class in the data set. Recall for the positive instances in the data set is called sensitivity. The sensitivity is the ratio of true positive to the real number of positive cases in the data set so that $sensitivity = \frac{TP}{TP + FN}$. Precision is a class-specific accuracy; it is the ratio of the number of correctly predicted instances of a class to the number of predicted instances of the same class. A specific case of precision for the negative class is called specificity. The specificity is the ratio of true negative to the real negative cases in the data set so that $specificity = \frac{TN}{TN + FP}$ [^19].

For a classifier, there is a trade-off between recall and precision; maximising one of them might cause the other to decline. Consequently, measures are introduced to overcome this problem and create a balance between these two measures. F-measure is computing the harmonic mean of the classes' recall and precision [^2] so that:
\begin{equation*}
F=\frac{2}{\frac{1}{precision} + \frac{1}{recall} } = \frac{2 \times precision \times recall}{precision + recall}
\end{equation*}

\acrfull{auc} of \acrfull{roc} is a measure used to calculate the performance of machine learning algorithms such as classification [^20] . The ROC curve is a graph of the true positive and false positive rates of the predicted classifier's result compared to the real class for each item. Figure 2.6 shows ROC curves for different algorithms with various performances. AUC is the area under the ROC curve plotted as a performance result of the classifier. Methods of calculating AUC vary according to the nature of application and available data. The multi-class AUCs are calculated using the equations of [^21]. $auc = \frac{2}{c(c-1)}\sum aucs$. Where c is number of classes and aucs is a set of auc between any two classes.

\begin{figure}[!h]

    \includegraphics[scale=0.4]{images/chapter2/AUC.png}
    \caption{Receiver operating characteristic (ROC) curves for various classifiers. From [^22]}
    \label{fig:ROC}

\end{figure}

---
_Reference_

[^1]: Kotsiantis, S. B. (2007) ‘Supervised machine learning: A review of classification techniques’, Informatica, 31, pp. 249–268. doi: 10.1115/1.1559160.
[^2]: Zaki, M. J. and Meira, M. J. (2014) Data Mining and Analysis: Fundamental Concepts and Algorithms, Cambridge University Press. New York: Cambridge University Press.
[^3]: Wu, X. et al. (2008) ‘Top 10 algorithms in data mining’, Knowledge and Information Systems, 14(1), pp. 1–37. doi: 10.1007/s10115-007-0114-2.
[^4]: Quinlan, J. R. (2014) C4.5: programs for machine learning. Elsevier (C4.5 - programs for machine learning / J. Ross Quinlan).
[^5]: Breiman, L. (2001) ‘Random forest’, Machine learning, 45(1), pp. 5--32. doi: 10.1017/CBO9781107415324.004.
[^6]: Hothorn, T., Hornik, K. and Zeileis, A. (2006) ‘Unbiased Recursive Partitioning: A Conditional Inference Framework’, Journal of Computational and Graphical Statistics, 15(3), pp. 651–674.
[^7]: Witten, I. H., Frank, E. and Hall, M. a. (2011) Data Mining: Practical Machine Learning Tools and Techniques, Third Edition. Morgan Kaufmann. doi: 10.1002/1521-3773(20010316)40:6<9823::AID-ANIE9823>3.3.CO;2-C.
[^8]: Rodriguez, A. et al. (2012) ‘Rule-based classification of power quality disturbances using S-transform’, Electric Power Systems Research, 86, pp. 113–121. doi: 10.1016/j.epsr.2011.12.009.
[^9]: Chen, C. S. (1996) ‘Statistical analysis of space-varying morphological openings with flat structuring elements’, IEEE Transactions on Signal Processing, 44(4), pp. 998–1001.
[^10]: Rodriguez, A. et al. (2012) ‘Rule-based classification of power quality disturbances using S-transform’, Electric Power Systems Research, 86, pp. 113–121. doi: 10.1016/j.epsr.2011.12.009.
[^11]: Chung, J. et al. (2002) ‘Power disturbance classifier using a rule-based method and wavelet packet-based hidden Markov model’, IEEE Transactions on Power Delivery, 17(1), pp. 233–241.
[^12]: McAulay, A. D. and Oh, J. C. (1994) ‘Improving Learning of Genetic Rule-Based Classifier’, IEEE Transactions on Systems, Man, and Cybernetics. IEEE, 24, pp. 152--159.
[^13]: Orriols-Puig, A. and Bernadó-Mansilla, E. (2009) ‘Evolutionary rule-based systems for imbalanced data sets’, Soft Computing, 13(3), pp. 213–225. doi: 10.1007/s00500-008-0319-7.
[^14]: Nozaki, K., Ishibuchi, H. and Tanaka, H. (1996) ‘Adaptive fuzzy rule-based classification systems’, IEEE Transactions on Fuzzy Systems, 4(3), pp. 238–250. doi: 10.1109/91.531768.
[^15]: Ishibuchi, H., Nozaki, K. and Tanaka, H. (1992) ‘Distributed representation of fuzzy rules and its application to pattern classification’, Fuzzy Sets and Systems, 52(1), pp. 21–32.
[^16]: Muller, K.-R. et al. (2001) ‘An introduction to kernel-based algorithms’, IEEE Transactions on Neural Networks, 12(2), pp. 181--202.
[^17]: Núñez, H., Angulo, C. and Català, A. (2006) ‘Rule-based learning systems for support vector machines’, Neural Processing Letters, 24(1), pp. 1–18. doi: 10.1007/s11063-006-9007-8.
[^18]: Wettschereck, D., Aha, D. W. and Mohri, T. (1997) ‘A Review and Empirical Evaluation of Feature Weighting Methods for a Class of Lazy Learning Algorithms’, Artificial Intelligence Review. Springer, 11(1--5), pp. 273--314. doi: 10.1023/A:1006593614256.
[^19]: Fawcett, T. (2006) ‘An introduction to ROC analysis’, Pattern Recognition Letters, 27(8), pp. 861–874. doi: 10.1016/j.patrec.2005.10.010.
[^20]: Bradley, A. P. (1997) ‘The use of the area under the ROC curve in the evaluation of machine learning algorithms’, Pattern Recognition, 30(7), pp. 1145–1159. doi: 10.1016/S0031-3203(96)00142-2.
[^21]: Hand, D. D. J. and Till, R. J. R. (2001) ‘A simple generalisation of the area under the ROC curve for multiple class classification problems’, Machine Learning, pp. 171–186.
[^22]: Alpaydin, E. (2010) Introduction to Machine Learning. London, England: The MIT Press. doi: 10.1007/s10994-009-5137-3.
